{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DB, USER ID, FOLLOWERS COUNT, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('allbrands_users_captions_list.csv')\n",
    "data = data[data['followers_count']>10000]\n",
    "data = data[data['followers_count']<100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_users = ['ana_brandine', 'vicky_regouli', 'luismiguelpss', 'ilariabiagini', \n",
    "              'emnegg', 'kerendhahn', 'agiorgina', 'roulamatta', 'jussbieber9827', \n",
    "              'eremiaheidr', 'eunhuiheo', 'anastasiakaps', 'achaelilsone', 'orit_talbi',\n",
    "              'sorayaalassmi', 'altonolnlis', 'vaso1977', 'theunrealobserver', 'nsb.koc',\n",
    "              'vivpeng', 'amrynevillek', 'danalev7', 'irienyree', 'lilachturgeman', \n",
    "              'emel_karakoc', 'thiswhomustbekept', 'j_f_lil', 'ulietteearneye', \n",
    "              'gilanaz', 'sarrahdolly', 'alexchahine97', 'photographerarson', \n",
    "              'angecanindo', 'fiona_smithson', 'chelsea_xu620']\n",
    "for i,v in enumerate(data.username): \n",
    "    for j, k in enumerate(list_users):\n",
    "        if str(v) == list_users[j]:\n",
    "            print(v)\n",
    "            \n",
    "    #### Note to Karan: \n",
    "    ### we need to pick our users. They don't match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe created at end of doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>aichanicole</td>\n",
       "      <td>14119</td>\n",
       "      <td>['Throwback #tokyo #trip #travel #lifestyle #a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>a_lifestyle_blog</td>\n",
       "      <td>13203</td>\n",
       "      <td>[\"Sometimes you'll just get those days where y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>bimbidotgirl</td>\n",
       "      <td>40185</td>\n",
       "      <td>['ü§ó #erdemxhm üíê Hai vinto üëèüèªüëèüèªüëèüèª', '... üîÆcosa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>aguademayozapatos</td>\n",
       "      <td>20600</td>\n",
       "      <td>['Absolutamente c√≥modos #tenis #massif #nuevac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>alexandalexacom</td>\n",
       "      <td>51246</td>\n",
       "      <td>['‚ùÑÔ∏è WINTER DAYS: COATS üå®\\r\\n\\r\\nTake your lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>bbberenger</td>\n",
       "      <td>15866</td>\n",
       "      <td>[\"J'ai oubli√© de me peigner les poils des bras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>cclaudiaff</td>\n",
       "      <td>10870</td>\n",
       "      <td>['‚ÄúIl #pinotnero √® come una bella ragazza con ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>begumtellioglu</td>\n",
       "      <td>19660</td>\n",
       "      <td>['‚ù§Ô∏è D u b a i ‚ù§Ô∏è #waitingfor #fountainshowdub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>alexandramiro</td>\n",
       "      <td>38932</td>\n",
       "      <td>['Excited to be working with our new press age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>_nina_pol</td>\n",
       "      <td>11362</td>\n",
       "      <td>['Œ©œÅŒ±ŒØŒ± Œ≥œÖŒΩŒ±ŒØŒ∫Œ± ŒµŒØŒΩŒ±Œπ Œ±œÖœÑŒÆ œÄŒøœÖ Œ∑ Œ≥ŒøŒ∑œÑŒµŒØŒ± œÑŒ∑œÇ Œµ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>alexanderdesignbuild</td>\n",
       "      <td>12979</td>\n",
       "      <td>['Dreamt of being here #daydream#chile#warm#sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>aliciaoficiall</td>\n",
       "      <td>17915</td>\n",
       "      <td>['Body time ‚ú® Body fluide dispon√≠vel na loja |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>alohacollection</td>\n",
       "      <td>21682</td>\n",
       "      <td>[\"Show your man some ALOHA with our new 'SEAL'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>abimfox</td>\n",
       "      <td>25502</td>\n",
       "      <td>['Congratulations @sydhayeshair on the launch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>abbyhorne_tv</td>\n",
       "      <td>13192</td>\n",
       "      <td>['Can we just take a minute to appreciate this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0              username  followers_count  \\\n",
       "0      14          14           aichanicole            14119   \n",
       "1      42          42      a_lifestyle_blog            13203   \n",
       "2      22          22          bimbidotgirl            40185   \n",
       "3     139         139     aguademayozapatos            20600   \n",
       "4      73          73       alexandalexacom            51246   \n",
       "5      51          51            bbberenger            15866   \n",
       "6      26          26            cclaudiaff            10870   \n",
       "7      52          52        begumtellioglu            19660   \n",
       "8      74          74         alexandramiro            38932   \n",
       "9     136         136             _nina_pol            11362   \n",
       "10    101         101  alexanderdesignbuild            12979   \n",
       "11    143         143        aliciaoficiall            17915   \n",
       "12    117         117       alohacollection            21682   \n",
       "13      8           8               abimfox            25502   \n",
       "14     44          44          abbyhorne_tv            13192   \n",
       "\n",
       "                                              caption  \n",
       "0   ['Throwback #tokyo #trip #travel #lifestyle #a...  \n",
       "1   [\"Sometimes you'll just get those days where y...  \n",
       "2   ['ü§ó #erdemxhm üíê Hai vinto üëèüèªüëèüèªüëèüèª', '... üîÆcosa ...  \n",
       "3   ['Absolutamente c√≥modos #tenis #massif #nuevac...  \n",
       "4   ['‚ùÑÔ∏è WINTER DAYS: COATS üå®\\r\\n\\r\\nTake your lit...  \n",
       "5   [\"J'ai oubli√© de me peigner les poils des bras...  \n",
       "6   ['‚ÄúIl #pinotnero √® come una bella ragazza con ...  \n",
       "7   ['‚ù§Ô∏è D u b a i ‚ù§Ô∏è #waitingfor #fountainshowdub...  \n",
       "8   ['Excited to be working with our new press age...  \n",
       "9   ['Œ©œÅŒ±ŒØŒ± Œ≥œÖŒΩŒ±ŒØŒ∫Œ± ŒµŒØŒΩŒ±Œπ Œ±œÖœÑŒÆ œÄŒøœÖ Œ∑ Œ≥ŒøŒ∑œÑŒµŒØŒ± œÑŒ∑œÇ Œµ...  \n",
       "10  ['Dreamt of being here #daydream#chile#warm#sa...  \n",
       "11  ['Body time ‚ú® Body fluide dispon√≠vel na loja |...  \n",
       "12  [\"Show your man some ALOHA with our new 'SEAL'...  \n",
       "13  ['Congratulations @sydhayeshair on the launch ...  \n",
       "14  ['Can we just take a minute to appreciate this...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = (data.sample(n=15)).reset_index()\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the ones that don't use english!\n",
    "\n",
    "\n",
    "# save to csv \n",
    "#.to_csv('usersused.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 56475 56475\n"
     ]
    }
   ],
   "source": [
    "#Saturday\n",
    "\n",
    "userlist=[]\n",
    "\n",
    "usernameforeachpost  = []\n",
    "f2post = []\n",
    "f3post = []\n",
    "\n",
    "for i,v in enumerate(dftest.username):\n",
    "    # save the usernames\n",
    "    userlist.append(v) \n",
    "    \n",
    "    captionsfromsample = dftest.caption\n",
    "    captionsfromsample = (pd.DataFrame(captionsfromsample)).reset_index()\n",
    "    captionsfromsample.drop(['index'], axis =1, inplace = True)\n",
    "    listof = []\n",
    "    for num, singlepost in enumerate(captionsfromsample.caption): \n",
    "        f1 = singlepost.split(\"\\', \\'\")\n",
    "        f3 = []\n",
    "\n",
    "        for j,k in enumerate(f1):\n",
    "            f2 = (f1[j].replace(\"\\n\", \" \")).replace(\"\\\\\", \"\")\n",
    "            f3.append(f2)\n",
    "            usernameforeachpost.append(v)\n",
    "            f2post.append(f2)\n",
    "            f3post.append(f3)\n",
    "        listof.append(f3)\n",
    "print(len(f2), len(f2post), len(usernameforeachpost))\n",
    "#df1991 = pd.DataFrame({'caption': f3post, 'username': usernameforeachpost})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1991 = pd.DataFrame({'caption': f2post, 'username': usernameforeachpost})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1991['polarity'] = np.zeros(len(df1991.caption))\n",
    "vectorizer = CountVectorizer(stop_words=['and', 'or', 'before', 'a', 'an', 'the']) #min_df=4\n",
    "corpus = df1991['caption'].values\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "x = x.toarray()\n",
    "y = df1991['polarity'].values\n",
    "\n",
    "## it outputs words\n",
    "## each line, token column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizer.vocabulary_\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56475, 14529) (56475,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,  y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listofwordspercluster = []\n",
    "#listofwords =[]\n",
    "clusteritison = []\n",
    "K=[]\n",
    "totallist = []\n",
    "\n",
    "for i in range(2,8):\n",
    "    true_k = i\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "    model.fit(x)\n",
    "\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "\n",
    "    for i in range(true_k):\n",
    "        #print(\"Cluster :\" , i+1)\n",
    "        listofwords = []\n",
    "        for ind in order_centroids[i, :-1]:\n",
    "            listofwords.append(terms[ind])\n",
    "        #print(listofwords)\n",
    "        totallist.append(listofwords)\n",
    "        #print(totallist)\n",
    "        #listofwordspercluster.append(listofwords)\n",
    "        clusteritison.append(int(i+1))\n",
    "        K.append(true_k)\n",
    "    \n",
    "DFofall = pd.DataFrame({'K_askedfor': K, 'clusternumber': clusteritison, 'listofwordspercluster':  totallist})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFofall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFofall.to_csv('clustersandwords.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
